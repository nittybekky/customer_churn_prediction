{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9deaf7fd-c5f3-4a24-9f50-9582a4a83454",
   "metadata": {},
   "source": [
    "\"\"\"This code base is adopted from the below notebook\n",
    "\n",
    "https://www.kaggle.com/code/edwingeevarughese/internet-service-churn-analysis\n",
    "'''\"\"\"\n",
    "\n",
    "Copyright (C) 2022 Intel Corporation\n",
    "SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "pylint: disable=C0209,C0301,W0108,C0103,E1101,E1137,E1136\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218d7a8-b1d7-4d1c-80ff-a39a4304826f",
   "metadata": {},
   "source": [
    "Industry: Telecommunications\n",
    "\n",
    "Aim: This task is aimed at predicting customers behavior in the telecommuniation.\n",
    "\n",
    "Task: Predict if a customer will unsubscribe and create churn or not (classification and regression)\n",
    "\n",
    "Dataset: Structured telecom internet subscriber data. the data set is made up of 72274 rows, and 11 columns\n",
    "\n",
    "Type of Learning: Supervised learning\n",
    "Models: Logistic regression, random forest classification\n",
    "Output: Yes or No if customer churn is predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29a32f-6f02-4477-8a62-a7c4fd4e7838",
   "metadata": {},
   "source": [
    "Use Case\n",
    "Our use case for this project was the Customer Churn Dataset sourced from kaggle\n",
    "(https://www.kaggle.com/datasets/mehmetsabrikunt/internet-service-churn) directory. \n",
    "\n",
    "Objectives\n",
    "Our objective is to determine whether a customer will leave the service provider and what could be the factor that sorround the customers behavior.\n",
    "\n",
    "We will fit 2 classification models and find the best model to describe our data. The models are:\n",
    "        Random Forest\n",
    "        Logistic Regression\n",
    "        \n",
    "Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f352594-d04c-48e6-a885-2a0fd02f3e2b",
   "metadata": {},
   "source": [
    "***** DATA DESCRIPTION *****\n",
    "\n",
    "Our data set has 72274 rows and 11 columns. Each entry contains the following information;\n",
    "\n",
    "       1. Id:This is customers unique identification number.\n",
    "\n",
    "       2. is_tv_subcriber: These are customers that subscribes to tv packages; 1 means subscriber where 0 means no subscriber\n",
    "        \n",
    "       3. is_movie_package_subscriber: Customers that subscribes to movie packages; 1 means subscriber where 0 means no subscriber\n",
    "\n",
    "       4. subscription_age: Age of the subscribers.\n",
    "        \n",
    "       5. bill_avg: customers billing average.\n",
    "        \n",
    "       6. reamining_contract: \n",
    "        \n",
    "       7. service_failure_count: This counts the number of times customer call to call center for service failure for last 3 months\n",
    "\n",
    "       8. download_avg\n",
    "\n",
    "       9. upload_avg\n",
    "        \n",
    "      10. download_over_limit\n",
    "        \n",
    "      11. churn: describes the loss of customers who don't resign their contract at the time of their renewal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12817e-eed2-47b8-860f-c1536873cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8cb1d-c8f6-47d4-9fba-251ee1257ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057b30b-1fe8-468e-a14e-9db06145286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = 'data/internet_service_churn.csv'\n",
    "\n",
    "#loaded the dataset from the data folder where it is saved.\n",
    "#and because the data set is in data folder we have to call the foldername and then the name of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4690f-d8e4-41a0-b225-e690007cf8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting track/ keeping record/ checking the system\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d59b0-a2ff-4570-b896-4830353d95ac",
   "metadata": {},
   "source": [
    "creating and defining model functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb946e2-2e14-4701-bf6f-441d2d729ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and error handlers to handle the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49b3a3-78d7-4057-b278-195e9e00639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmodel(modelfile):\n",
    "    \"\"\"Loading the saved joblib model\"\"\"\n",
    "    try:\n",
    "        load_model = joblib.load(modelfile)\n",
    "    except Exception as excep:\n",
    "        raise IOError(\"Error loading model data from disk: {}\".format(str(excep))) from excep\n",
    "    return load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dfd86-3301-4614-9f24-2b09370d1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the result output of the trained model for future prediction.\n",
    "def savemodel(save_model, modelfile):\n",
    "    \"\"\"Saving the joblib model\"\"\"\n",
    "    try:\n",
    "        joblib.dump(save_model, modelfile)\n",
    "    except Exception as exp:\n",
    "        raise IOError(\"Error saving model data to disk: {}\".format(str(exp))) from exp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975bdb1-6139-4db1-be68-7b6681575aea",
   "metadata": {},
   "source": [
    "##  preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071bfda-f3a3-4b5c-9eb2-71a94d6d13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_preparation(data_max_size, test_split):\n",
    "    \"\"\"Data Preparation \"\"\"\n",
    "    # Data preparation Starts here\n",
    "    start_time = time.time()\n",
    "    # loading data\n",
    "    try:\n",
    "        df = pd.read_csv(DATASET_FILE) # reading the data set file\n",
    "    except IOError:  # noqa:F841\n",
    "        sys.exit('Dataset file not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fed9e-8fb8-4b96-8ae3-095795f4dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(DATASET_FILE)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c8202-9523-41a2-928b-a4a1ad331ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating is_contract column\n",
    "df['is_contract'] = df['reamining_contract'].apply(lambda ele: 0 if pd.isna(ele) else 1)\n",
    "    # Imputing null values with 0\n",
    "df['reamining_contract'].replace(np.nan, 0, inplace=True)\n",
    "    # Rearranging columns\n",
    "column_names = ['id', 'is_tv_subscriber', 'is_movie_package_subscriber', 'subscription_age', 'bill_avg',\n",
    "                    'reamining_contract',\n",
    "                    'is_contract', 'service_failure_count', 'download_avg', 'upload_avg', 'download_over_limit',\n",
    "                'churn']\n",
    "\n",
    "df = df.reindex(columns=column_names)\n",
    "\n",
    "df['download_avg'].replace('', np.nan, inplace=True)\n",
    "df['upload_avg'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['download_avg', 'upload_avg'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e92ece-537d-4b40-b7aa-022c91ad7e2f",
   "metadata": {},
   "source": [
    "\n",
    "Observation\n",
    "Another column was created called is_contract column \n",
    "The code in line was identifying and replacing null values with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9e9fa-9c50-49f1-8798-44a630c0fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the current number of rows and columns after the replacement\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5e9f7-f68a-4ca7-9a13-8920dc2276ad",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Restructuring as per the correlation across the features\n",
    "# the columns values of the data set are re-arranged in ascending order\n",
    "df.corr()['churn'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79263cf-d907-4591-99ba-fa326af706cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295fa85-d558-425d-9676-f08d7a93e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up training and Label features for training\n",
    "x = df.drop(columns=['churn'])\n",
    "y = df['churn'].values\n",
    "\n",
    "if data_max_size != x.shape[0]:\n",
    "    x = x.head(data_max_size)\n",
    "    y = y[:data_max_size]\n",
    "logger.info('[Data] DataPreparation Time Taken in seconds --> %f secs', time.time() - start_time)\n",
    "logger.info('[Data] Total Data samples ---> %s', x.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b58a1-1e30-4f5a-99f2-d3ab9f6ab596",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Preparing dataset for Training\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_split, random_state=40, stratify=y)\n",
    "    # Since the numerical features are distributed over different value ranges,\n",
    "    # standard scalar is used to scale them down to the same range.\n",
    "    num_cols = ['subscription_age', 'reamining_contract', 'download_avg', 'upload_avg',\n",
    "                'download_over_limit', 'bill_avg', 'service_failure_count']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_train[num_cols] = scaler.fit_transform(x_train[num_cols])\n",
    "    x_test[num_cols] = scaler.transform(x_test[num_cols])\n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
